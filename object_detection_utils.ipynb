{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object-detection-utils",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owahltinez/object-detection-utils/blob/main/object_detection_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download prebuilt object_detection library binaries and data\n",
        "!wget -c -q https://github.com/owahltinez/object-detection-utils/releases/download/462bb852d/object_detection-0.1-py3-none-any.whl\n",
        "!wget -c -q https://github.com/owahltinez/object-detection-utils/releases/download/462bb852d/ducky.zip && rm -rf ducky && unzip -q -d ducky ducky.zip\n",
        "!pip install object_detection-0.1-py3-none-any.whl > /dev/null\n",
        "!rm -rf object_detection-0.1-py3-none-any.whl ducky.zip"
      ],
      "metadata": {
        "id": "pEaJmcDICE3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download object-detection-utils libraries\n",
        "!git clone --depth 1 https://github.com/owahltinez/object-detection-utils\n",
        "!mv object-detection-utils/* .\n",
        "!rm -rf object-detection-utils"
      ],
      "metadata": {
        "id": "0k9MihX7Bb98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and utility functions\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "# These are the object-detection-utils library imports.\n",
        "import dataset_util\n",
        "import keras_model_wrapper\n",
        "import pretrained_models\n",
        "\n",
        "def plot_detections(\n",
        "    image_np,\n",
        "    boxes,\n",
        "    classes,\n",
        "    scores,\n",
        "    category_index,\n",
        "):\n",
        "  annotated_image = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      annotated_image,\n",
        "      boxes,\n",
        "      classes,\n",
        "      scores,\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.5)\n",
        "  display(Image.fromarray(annotated_image))"
      ],
      "metadata": {
        "id": "D0OmGV3YSyq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the pretrained detection model\n",
        "detection_model = pretrained_models.load_detection_model('ssd_resnet50_v1_fpn_640x640', num_classes=1)"
      ],
      "metadata": {
        "id": "QPsprtb4_zgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert it into a keras compatible model\n",
        "keras_model = keras_model_wrapper.KerasModelWrapper(detection_model)"
      ],
      "metadata": {
        "id": "RjAkEZ7l_7Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create train image dataset\n",
        "train_image_dir = 'ducky/train/'\n",
        "image_paths = [os.path.join(train_image_dir, f) for f in sorted(os.listdir(train_image_dir))]\n",
        "detection_boxes = [\n",
        "    [[0.436, 0.591, 0.629, 0.712]],\n",
        "    [[0.539, 0.583, 0.73, 0.71]],\n",
        "    [[0.464, 0.414, 0.626, 0.548]],\n",
        "    [[0.313, 0.308, 0.648, 0.526]],\n",
        "    [[0.256, 0.444, 0.484, 0.629]],\n",
        "]\n",
        "detection_classes = [[1]] * len(image_paths)\n",
        "\n",
        "ds = dataset_util.image_dataset_from_paths(\n",
        "    image_paths,\n",
        "    detection_boxes,\n",
        "    detection_classes,\n",
        "    batch_size=5,\n",
        ")"
      ],
      "metadata": {
        "id": "409O1S5wAJ0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fine-tune the model using the training data\n",
        "\n",
        "# Use specific variables for fine-tuning and keep the rest frozen.\n",
        "prefixes_to_train = [\n",
        "    \"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead\",\n",
        "    \"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead\",\n",
        "]\n",
        "trainable_variables = []\n",
        "for model_variable in detection_model.trainable_variables:\n",
        "    if any([model_variable.name.startswith(prefix) for prefix in prefixes_to_train]):\n",
        "        trainable_variables.append(model_variable)\n",
        "keras_model.set_trainable_variables(trainable_variables)\n",
        "\n",
        "keras_model.compile(optimizer=tf.keras.optimizers.Adam(), run_eagerly=True)\n",
        "keras_model.fit(ds.unbatch().cache().shuffle(100).batch(5), epochs=100);"
      ],
      "metadata": {
        "id": "7kgdS3zWCJKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run inference using unseen test data\n",
        "\n",
        "category_index = {1: {'id': 1, 'name': 'rubber_ducky'}}\n",
        "test_image_dir = 'ducky/test/'\n",
        "image_paths = [os.path.join(test_image_dir, f) for f in sorted(os.listdir(test_image_dir))]\n",
        "image_arrays = [dataset_util.read_image_tensor(p) for p in image_paths]\n",
        "\n",
        "for image in image_arrays:\n",
        "  pred = keras_model.predict(tf.expand_dims(image, axis=0), verbose=0)\n",
        "  # Retrieve only the first prediction, since it's a single-item batch.\n",
        "  pred = {k: v[0] for k, v in pred.items()}\n",
        "  plot_detections(\n",
        "    image.numpy().astype(np.uint8),\n",
        "    pred['detection_boxes'],\n",
        "    pred['detection_classes'],\n",
        "    pred['detection_scores'],\n",
        "    category_index,\n",
        "  )"
      ],
      "metadata": {
        "id": "HXaWKVWCCcu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}